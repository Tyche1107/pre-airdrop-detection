# Pre-Airdrop Sybil Detection

## Four Core Findings

**1. Pre-airdrop detection outperforms post-hoc GNN.**
Using only on-chain behavior strictly before the distribution event, LightGBM achieves AUC 0.905 at T-30 on Blur and AUC 0.946 at T-30 on LayerZero — both exceeding ARTEMIS (0.803), which uses full post-hoc graph data including transfer edges generated by the airdrop itself.

**2. Graph neural networks fail structurally before the airdrop.**
ArtemisNet (AUC 0.976 post-hoc) collapses to AUC 0.586 at T-30. The cause is architectural: GNN edges include transfer events that only exist after distribution. Remove those edges and the graph is structurally incomplete. This is not a tuning problem — it is a fundamental incompatibility between graph methods and the pre-airdrop setting.

**3. The behavioral signal is stable months in advance.**
Blur: AUC drops only 0.013 from T-0 to T-180. LayerZero: AUC range is 0.0006 across T-30 to T-90 — essentially flat. Sybil hunters build identifiable behavioral fingerprints (collection diversity, unique contract breadth) long before they claim rewards, and those fingerprints do not change as the event approaches.

**4. Evasion is economically self-defeating.**
Reducing behavioral diversity by 90% to evade detection drops AUC by only 0.6% — but costs the attacker 67% of accumulated incentive points. The detection system is game-theoretically stable: rational sybil hunters cannot evade without destroying their own reward.

---

ARTEMIS (WWW'24) asks: who claimed the airdrop sybilically? We ask a different question: can we identify them before they claim, using only what was observable on-chain in advance? The answer is yes, substantially, and months in advance — on both NFT and bridge protocols.

## Key Results

| Finding | Detail |
|---------|--------|
| **Pre-airdrop detection beats post-hoc GNN** | Blur: AUC 0.905 (T-30). LayerZero: AUC 0.946 (T-30). Both exceed post-hoc ARTEMIS 0.803 using only pre-airdrop data |
| **GNN fails structurally before airdrop** | ArtemisNet collapses from 0.976 (post-hoc) to 0.586 (T-30) — architectural failure, not tuning |
| **Signal flat for 6 months** | Blur: 0.013 drop from T-0 to T-180. LayerZero: 0.0006 range across T-30/60/90 |
| **Evasion is economically self-defeating** | 90% diversity reduction: AUC drops 0.6%, incentive points drop 67% |
| **In-domain: robust across two protocol types** | Blur 0.905, LayerZero 0.946 — both with protocol-specific training |
| **Zero-shot transfer: limited without target data** | Same-class bridge (Hop→LZ): 0.567. Cross-domain (Blur→LZ): 0.434. Common-feature set improves Blur→Hop to 0.78 |
| **Two-stage detector handles unseen sybil types** | BW-type left out: supervised AUC 0.047 → Isolation Forest AUC 0.916 |

> **Adversarial robustness highlight:** Sybil evasion is economically irrational. A sybil hunter who reduces behavioral diversity by 90% to evade detection loses 67% of their accumulated incentive points, while AUC drops by only 0.6%. The economic cost of evasion far exceeds any benefit, making the detection system game-theoretically stable.

## The Story in Five Acts

### Act 1: Why GNN Fails Before the Airdrop

ARTEMIS (WWW'24) uses ArtemisNet, a GNN that achieves AUC 0.976 post-hoc. We replicate it on the same data and confirm: post-hoc, it is excellent. Then we apply it at T-30, removing transaction edges that only exist after the airdrop is distributed. AUC collapses to 0.586.

This is not a tuning failure. GNN edges encode who transferred tokens to whom after the airdrop — structural information that does not exist before the event. A method that depends on those edges cannot be repurposed for pre-airdrop detection without re-engineering the core architecture. This motivates the behavioral feature approach entirely.

| Script | Purpose | Key result |
|--------|---------|------------|
| 09_artemis_gnn.py | Reproduce ArtemisNet post-hoc, 5-fold CV | AUC 0.976 — confirms the post-hoc upper bound |
| 15_gnn_preairdrop.py | Apply ArtemisNet at T-30 (no post-distribution edges) | AUC 0.586 — structural collapse, not a tuning problem |

### Act 2: Behavioral Features Work, and Earlier Than Expected

Sybil hunters spread transactions across many NFT collections to accumulate points. This behavioral pattern — diversity across collections, breadth of contract interactions — is observable months before the airdrop and is structurally different from genuine collectors. Eighteen features computed from raw pre-airdrop transactions (no graph, no post-hoc data) achieve AUC 0.905 at T-30, outperforming ARTEMIS by 10 points.

The dominant feature is NFT collection diversity (37-49% importance across time windows). The second most time-sensitive feature is unique contract interactions: its importance rises from 7% to 22% as the window extends to T-90, capturing the early batch-wallet creation pattern that predates the farming sprint.

| Script | Purpose | Key result |
|--------|---------|------------|
| 01_build_features.py | Extract 18 behavioral features with strict timestamp cutoff | Preprocessing; prevents data leakage |
| 02_train_lightgbm.py | LightGBM 5-fold CV at T-30 vs ARTEMIS baseline | AUC 0.905 vs ARTEMIS 0.803 |
| 03_temporal_ablation.py | Sweep T-0 to T-90 | T-0: 0.908, T-30: 0.905, T-90: 0.902 |
| 12_extended_temporal.py | Extend sweep to T-120, T-150, T-180 | T-180: 0.895; total drop over 6 months is 0.013 |

Feature group ablation (each group trained independently, Exp 06):

| Group | Features | AUC |
|-------|----------|-----|
| All 18 | — | 0.903 |
| Activity | buy/sell/tx counts | 0.863 |
| Diversity | collections, unique interactions | 0.854 |
| Behavioral | sell ratio, wallet age, recency | 0.848 |
| Volume | buy/sell ETH value | 0.846 |
| DeFi | Blend lending activity | 0.544 |

DeFi contributes almost nothing because sybil strategy targets NFT transactions, not Blur's Blend lending product. Diversity and Activity carry the bulk of the signal.

### Act 3: The Signal is Stable Six Months in Advance

The 0.013 total drop from T-0 to T-180 means the behavioral fingerprint does not meaningfully change as the event approaches. Sybil hunters cannot hide their pattern by frontloading activity close to the deadline — the structural difference from genuine collectors builds up over months and stays.

Generalization across held-out splits:

| Test | Setting | AUC |
|------|---------|-----|
| Standard 5-fold CV | T-30 | 0.905 |
| Temporal split | Train T-90, test T-30 | 0.898 |
| Population split | 50% unseen sybil subtypes | 0.744 |

The population split at 0.744 reveals the known failure mode: three behavioral subtypes exist (retail hunters, mid-volume, hyperactive bots), and the model generalizes well across most of them — except for BW (high-value buyer) sybils, which the model was never trained to associate with sybil behavior. This sets up Act 4.

### Act 4: Attackers Cannot Evade Cheaply

Two scenarios: active evasion (can a sybil hunter game the model?) and unknown types (what if a new strategy appears?).

**Active evasion (Exp 23):** A sybil hunter who reduces behavioral diversity by 90% would reduce AUC from 0.904 to 0.899 — a 0.6% drop. But they would also lose 67% of accumulated incentive points. The economic cost of evasion far exceeds the marginal benefit. The detection system is game-theoretically stable.

**Unknown sybil type — BW (Exp 21 + 25):** BW-type sybils (high buy_value, fewer collections) are excluded from training. Supervised model: AUC 0.047. They are invisible to the supervised detector. Isolation Forest (unsupervised), however, detects them at AUC 0.916, because they are statistical outliers in feature space regardless of labeling. A two-stage deployment (LightGBM for known types, IF for anomalies) is robust to novel strategies.

| Script | Purpose | Key result |
|--------|---------|------------|
| 23_adversarial_cost.py | Economic cost of diversity-reduction evasion | 90% cut: AUC -0.6%, incentive points -67% |
| 21_flag_type_generalization.py | Leave-one-type-out: BW, FD, ML, HF | BW: 0.047; others: 0.110-0.550 |
| 25_openworld_detection.py | Two-stage: LightGBM + Isolation Forest | IF raises BW from 0.047 to 0.916 |

### Act 5: The Story Holds on a Second Protocol

Everything above is on Blur, a single airdrop event. Is the signal Blur-specific, or is it real?

Experiment 28 applies the identical pipeline to LayerZero ZRO (June 2024 airdrop, 29.8K addresses). AUC 0.9462 at T-30, 0.9468 at T-60, 0.9462 at T-90. Temporal range: 0.0006 across three months — flatter than Blur's 0.003. This exceeds both Blur (0.905) and the LayerZero in-domain estimate from Exp 24 (0.892).

The same four acts play out on a bridge protocol: behavioral fingerprints exist, they are detectable months in advance, the signal is stable, and evasion economics hold.

| Script | Purpose | Key result |
|--------|---------|------------|
| 28_layerzero_temporal.py | Full temporal ablation on LZ (same pipeline as Exp 03) | T-30: 0.9462 (17,072 active), T-60: 0.9468, T-90: 0.9462; range 0.0006 |
| 24_layerzero_lopo.py | Zero-shot cross-protocol to LZ as context | Hop→LZ: 0.567, Blur→LZ: 0.434; in-domain bound 0.892 |

Zero-shot cross-protocol transfer (0.43-0.57) is limited because sybil fingerprints are protocol-specific in their feature expression. In-domain training is required for strong results. Zero-shot transfer improves significantly with common features (Blur→Hop: 0.38 → 0.78, Exp 17) and recovers fully with 1% target labels (Exp 14, 16b).

## Supporting Experiments

Experiments that confirm and extend the five acts above; intended for supplementary material in any paper submission.

| Script | Confirms | Result |
|--------|---------|--------|
| 04_feature_importance.py | Act 2: feature stability across time | Diversity 37-49%; unique_interactions 7-22% |
| 05_pr_analysis.py | Act 3: deployment threshold selection | Precision-recall trade-off curve |
| 07_graph_features.py | Act 2: graph features add marginal value | Behavioral+graph 0.905 vs behavioral alone 0.904 |
| 10_shap_analysis.py | Act 2: confirms feature ranks via SHAP | Diversity + unique_interactions top contributors |
| 11_sybil_clustering.py | Act 3: sybil subtype structure | K=3: 49K retail, 601 mid-volume, 6 bots |
| 13_adversarial_robustness.py | Act 4: full evasion sweep | AUC 0.904 → 0.899 across 0-90% diversity reduction |
| 14_cross_protocol.py | Act 5: Hop fine-tuning budget | 1% labels recovers AUC 0.982 |
| 16_lopo_crossprotocol.py | Act 5: protocol-specific features cause the gap | AUC 0.22-0.47 with protocol-specific features |
| 16b_lopo_blur_hop.py | Act 5: label-budget recovery | 300 labels sufficient for full recovery |
| 17_common_features_lopo.py | Act 5: common features close the gap | Blur→Hop: 0.38 → 0.78 |
| 18_gitcoin_feature_importance.py | Act 5: Gitcoin label quality | gitcoin_donations = 0% importance |
| 19_shap_temporal.py | Act 2: SHAP shift across windows | T-90: wallet_age dominant; T-7: recent_activity |
| 20_clustering_k_selection.py | Act 3: K justification | K=3 for semantic separation over K=2 |
| 22_calibration.py | Act 3: probability calibration | Brier score -24%; AUC unchanged |
| 26_label_noise.py | Act 4: blacklist imperfection resilience | 20% label flip: AUC -0.014 |
| 27_rule_baselines.py | Act 2: simple heuristics vs LightGBM | Best rule: 0.610; LGB: 0.905 |

## Datasets and Data Sources

Each dataset uses a different source for on-chain features. This section documents exactly where the data comes from.

### Blur (primary dataset)

| Item | Detail |
|------|--------|
| Source | Blur NFT marketplace transaction logs, Season 2 (Feb-Nov 2023) |
| Raw data | `TXS2_1662_1861.csv` — 3.2M NFT transactions, 251K unique addresses |
| Labels | Blur official `airdrop2_targets` sybil list — binary is_sybil |
| T0 | 1700525735 (2023-11-21 00:15:35 UTC, first Season 2 claim) |
| Feature pipeline | `01_build_features.py` — 18 features computed directly from raw transaction CSV, no external API calls |

### Hop Protocol (cross-protocol, Exp 14/16/17)

| Item | Detail |
|------|--------|
| Source | Hop bridge transaction history |
| Labels | Hop Sybil Hunter program official list |
| Feature pipeline | Protocol-specific features; common 5-feature set for cross-protocol transfer (tx_count, total_volume, wallet_age_days, unique_contracts, active_span_days) |

### Gitcoin GR15 (cross-protocol, Exp 16/17/18)

| Item | Detail |
|------|--------|
| Source | Gitcoin Grants Round 15 on-chain data |
| Labels | SADScore — Sybil Address Detection scores as binary labels |
| Addresses | 39,962 addresses |
| On-chain features | Fetched via **Etherscan V2 API** (`api.etherscan.io/v2/api`), multiple keys in parallel (`fetch_gitcoin_onchain.mjs`) |

### LayerZero ZRO (cross-protocol, Exp 24 and Exp 28)

**Exp 24** (`multichain_features.csv`) and **Exp 28** (`lz_temporal_features.csv`) use the same address list but different feature pipelines:

| Item | Detail |
|------|--------|
| Addresses | 29,849 total; 19,480 active (total_tx > 0); 9,899 sybil / 9,581 normal |
| Labels | LayerZero official "Proof of Sybil" campaign results |
| T0 | 1718841600 (2024-06-20 00:00 UTC, ZRO airdrop) |

**Exp 24 features** (`multichain_features.csv`):
- Fetched via **Etherscan V2 API** across 3 chains: ETH mainnet, Arbitrum, Polygon
- Keys: two rotating Etherscan API keys, 5 req/s each
- Script: `fetch_lz_features.mjs` — aggregated chain-level features summed across chains
- Covers: tx_count, wallet_age_days, unique_contracts, active_span_days, total_volume per chain and cross-chain total

**Exp 28 features** (`lz_temporal_features.csv`):
- Fetched via **Alchemy API** (`alchemy_getAssetTransfers`, ETH mainnet only)
- Alchemy key used: `dPr_w2ES924h7eiMOHbeM` (app at dashboard.alchemy.com)
- Script: `fetch_lz_alchemy.mjs` — 30 concurrent workers, ~100 addresses/second
- Temporal cutoffs computed from same data: T-30 (1716249600), T-60 (1713657600), T-90 (1711065600)
- **Limitation**: ARB and POLY networks not yet enabled in the Alchemy app. Exp 28 features are ETH-mainnet only. Re-running after enabling ARB/POLY will produce more complete cross-chain features.

### Known Data Limitation (Exp 28)

Exp 28 uses ETH-only behavioral features for a bridge protocol (LayerZero) whose core utility is cross-chain. This means the T-30/60/90 features capture Ethereum-side activity (token approvals, contract interactions before bridging) but miss the destination-chain behavior. Despite this limitation, Exp 28 achieves AUC 0.946, suggesting the pre-bridge Ethereum-side behavior alone is sufficient for detection. Adding ARB/POLY features is expected to improve results further.

## Reproducibility

All temporal cutoffs are enforced by filtering on raw transaction timestamps before any feature computation. Features at T-k use only transactions with timestamp less than (T0 minus k days in seconds). Labels are applied after feature computation and are never used to select which transactions to include. The Blur T0 is 1700525735 (first Season 2 claim transaction, 2023-11-21 00:15:35 UTC).
